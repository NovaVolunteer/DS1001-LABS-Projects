{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435198a8",
   "metadata": {
    "id": "435198a8"
   },
   "source": [
    "# LABS-9: Analytics Project\n",
    "\n",
    "In this notebook you will run and edit the code to perform some data cleaning and run a basic kNN model.\n",
    "\n",
    "> **What is kNN?**\\\n",
    "k-Nearest Neighbors (kNN) is a machine learning algorithm used for classification tasks. At its core, kNN works by measuring the \"distance\" between data points. When you want to predict the category of a new data point, kNN looks at the 'k' closest points in your dataset (its \"neighbors\") and assigns the most common category among those neighbors to the new point.\n",
    "\n",
    "> **How does kNN measure distance?**\\\n",
    "kNN relies on distance metrics - commonly Euclidean distance (the straight-line distance between two points) - to find which data points are most similar. The algorithm compares all features (columns) in your dataset, so it's important that these features are numeric or converted to a format where distances can be calculated.\n",
    "\n",
    "> **How will we use kNN here?**\\\n",
    "In this notebook, we'll use kNN for classification: predicting whether a movie will receive a \"high\" or \"low\" score based on its features (like genre, country, budget, and more). By carefully cleaning and formatting our data, we ensure that kNN can measure distances and make meaningful predictions.\n",
    "\n",
    "**Data**\\\n",
    "This dataset comes from IMDB and can be accessed on [Kaggle](https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617ebe9",
   "metadata": {
    "id": "0617ebe9"
   },
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad392be",
   "metadata": {
    "id": "3ad392be"
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "\n",
    "import pandas as pd #data ingestion & cleaning\n",
    "import numpy as np #numbers\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ashpalsingh1525/imdb-movies-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsv9nav5yIMR",
    "outputId": "28f77e56-ac2f-4452-99b8-cce302fcaf58"
   },
   "id": "vsv9nav5yIMR",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7d52e",
   "metadata": {
    "id": "4eb7d52e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "outputId": "288296da-8cf5-40d8-8b40-83f279fd8a41"
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('insert file path here')\n",
    "\n",
    "# view data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ff1aa",
   "metadata": {
    "id": "d94ff1aa"
   },
   "source": [
    "## Data Cleaning & Model Prep\n",
    "\n",
    "Before building a machine learning model, it is essential to clean and format the data. Raw data often contains missing values, inconsistent formats, or irrelevant information that can negatively impact or break a model.\\\n",
    "Many algorithms, including kNN, require numeric input or specificly formatted categorical data. By cleaning the data (removing or imputing missing values, converting strings to categorical variables, and creating dummy variables), we ensure that our dataset is structured in a way that the model can interpret and learn from effectively.\n",
    "\n",
    "Proper data preparation leads to more accurate, reliable, and interpretable results.\n",
    "\n",
    "There are many decisions that get made throughout this process and there is often no \"right\" answer - so documentating why you do things as you clean data is **key**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8dfb6",
   "metadata": {
    "id": "15c8dfb6"
   },
   "source": [
    "### Missing Values\n",
    "\n",
    "We saw in our design lab that some of our columns are missing values. Many models can not tolerate missing data (they will break the model), so we have to deal with these before passing the data through to our model.\n",
    "\n",
    "We can use the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info) method to see what columns are missing data. Run this below (look back at LABS-06 if you don't remember how)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d1c37",
   "metadata": {
    "id": "fe5d1c37"
   },
   "outputs": [],
   "source": [
    "# ADD THE CODE TO RUN .INFO() ON THE DATA HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c1d68",
   "metadata": {
    "id": "e17c1d68"
   },
   "source": [
    "2 columns are missing data: `genre` and `crew`.\\\n",
    "Since we have a large data set for kNN, we can drop the relatively few rows that are missing data using .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7a61e",
   "metadata": {
    "id": "18e7a61e"
   },
   "outputs": [],
   "source": [
    "## make a new df to make changes to\n",
    "model_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2815f",
   "metadata": {
    "id": "fbc2815f"
   },
   "outputs": [],
   "source": [
    "# drop rows containing NaN (missing) values\n",
    "model_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116254da",
   "metadata": {
    "id": "116254da"
   },
   "source": [
    "Now that we've dropped rows with missing values, our dataset is free of NaNs.\n",
    ">The output of the cell below (`model_data.info()`) confirms that all columns are complete and can be used to answer **question 1** regarding how much data was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619b527",
   "metadata": {
    "id": "b619b527",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b52e9795-44ac-4536-822f-8ff8149dbd33"
   },
   "outputs": [],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf65e6",
   "metadata": {
    "id": "10cf65e6"
   },
   "source": [
    "### Look at Columns\n",
    "\n",
    "When preparing data for kNN, it's important to look at the values in each column, especially for columns with categories (like country or genre).\\\n",
    "kNN works by measuring the distance between data points to find the ones that are most similar, so if a column has too many different categories, it can make these distance calculations confusing and less useful. If some categories only appear a few times, they don't help much and can make the model less accurate.\n",
    "\n",
    "To fix this, we can group these less common categories into a single 'other' category. This makes the data simpler and helps kNN focus on the most useful information when measuring distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c646d82",
   "metadata": {
    "id": "5c646d82",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "outputId": "618dc27a-b764-492e-dbd2-a134135d1620"
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf640ed",
   "metadata": {
    "id": "caf640ed"
   },
   "source": [
    "The `status` column has 3 levels (3 distrinct values in the column). This works great for kNN!\n",
    "\n",
    "Now let's take a look at `country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d083f61",
   "metadata": {
    "id": "9d083f61",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "cb85fce0-98b5-4c3a-e7cd-4d229e10e7b9"
   },
   "outputs": [],
   "source": [
    "data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfaa9f5",
   "metadata": {
    "id": "3bfaa9f5"
   },
   "source": [
    "`country` has far too many columns to use in kNN. We need to collapse the smaller countries into a single \"other\" category.\n",
    "\n",
    "In the next code cell, you will run the code to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39bbf8",
   "metadata": {
    "id": "9c39bbf8"
   },
   "source": [
    "#### Collapse the `country` column\n",
    "\n",
    "The cell below contains the code to collapse the `country` column reassign any coutries with less occurances than the threshold to have the value 'other'.\n",
    "\n",
    "> *Hint: Look at the variable assignment in the cell below to identify where the threshold for grouping countries is set to help answer **question 3**. Notice where this is used in the line below the does the actual collapsing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467c407",
   "metadata": {
    "id": "4467c407"
   },
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "model_data['country'] = model_data['country'].apply(lambda x: x if model_data['country'].value_counts()[x] > threshold else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b653ce",
   "metadata": {
    "id": "d6b653ce",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "outputId": "20bb0ab0-133b-4ce2-86fa-536a936ac31e"
   },
   "outputs": [],
   "source": [
    "# check the new counts after collapsing\n",
    "\n",
    "model_data['country'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec316b2b",
   "metadata": {
    "id": "ec316b2b"
   },
   "source": [
    "Now the `country` column has 11 levels, including our new \"other\" category. This is still a little large for kNN, but we can always come back and adjust this if we find our model needs some tinkering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9d780",
   "metadata": {
    "id": "70f9d780"
   },
   "source": [
    "#### Look at other problematic columns\n",
    "\n",
    "Now let's check out some of the other categorical columns that we'll use and see if we need to collapse or simplify any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8ab6d",
   "metadata": {
    "id": "d8e8ab6d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "outputId": "c2103421-11e9-43db-c6f6-6bf3e04500e4"
   },
   "outputs": [],
   "source": [
    "# Check values for 'genre' column\n",
    "\n",
    "model_data['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d49a5",
   "metadata": {
    "id": "900d49a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "1031e838-d4e1-47c4-ab24-278a008e52bd"
   },
   "outputs": [],
   "source": [
    "# Check values for 'orig_lang' column\n",
    "\n",
    "model_data['orig_lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba9358",
   "metadata": {
    "id": "fcba9358"
   },
   "source": [
    "Both the `genre` and `orig_lang` columns often contain multiple values separated by commas within a single cell (for example, \"Animation, Adventure, Family\" or \"Spanish, Castilian\"). This means that instead of just one value, each cell can list several genres or languages for a movie.\n",
    "\n",
    "This is too complex for machine learning models like kNN, which work best when each column contains just one clear value per row. To make things simpler and easier to model, we will only keep the first value from each cell. This way, each movie will have just one genre and one language listed, making our data cleaner and better suited for the modeling we are doing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb6b0d",
   "metadata": {
    "id": "fbcb6b0d"
   },
   "source": [
    "#### Get the first value for `genre` and `orig_lang`\n",
    "\n",
    "\n",
    "This process happens in three steps:\n",
    "\n",
    "1. **Define the function:**  \n",
    "    To simplify columns that contain lists of values, we we use a **function** - a reusable block of code that performs a specific task. Think of a function like a mini-program: you give it some input, it does something for you, and gives you back a result. Here, our function will extract just the first value from each cell to simplify the data so each row has only one value per column.\n",
    "\n",
    "2. **Apply the function:**  \n",
    "    We then apply this function to the `genre` and `orig_lang` columns, creating new columns called `top_genre` and `top_lang` with just the top value for each movie.\n",
    "\n",
    "3. **Recheck the counts:**  \n",
    "    After this step, we check how many unique values remain in these simplified columns to confirm that our data is now easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862249a",
   "metadata": {
    "id": "8862249a"
   },
   "outputs": [],
   "source": [
    "# define the function to simplify the columns\n",
    "\n",
    "def get_top_value(old_column_name, new_column_name):\n",
    "    \"\"\"\n",
    "    Function to extract the first value from a column that contains multiple comma seperated values\n",
    "    Appends a new column to the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    col = list(model_data[old_column_name].values)\n",
    "\n",
    "    top_list = []\n",
    "    for item in col:\n",
    "        item = str(item).split(\",\")\n",
    "        item1 = item[0]\n",
    "        top_list.append(item1)\n",
    "\n",
    "    model_data[new_column_name] = top_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917ee05",
   "metadata": {
    "id": "e917ee05"
   },
   "outputs": [],
   "source": [
    "# apply the function to the 'genre' and 'orig_lang' columns\n",
    "\n",
    "get_top_value('genre', 'top_genre')\n",
    "get_top_value('orig_lang', 'top_lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf9acf",
   "metadata": {
    "id": "daaf9acf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "29241625-f097-4a26-82c4-71936adc85d5"
   },
   "outputs": [],
   "source": [
    "# Check the counts again\n",
    "\n",
    "display(model_data['top_genre'].value_counts(),\n",
    "        model_data['top_lang'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d3a31",
   "metadata": {
    "id": "017d3a31"
   },
   "source": [
    "The `top_genre` column now has 19 different values, which is easier for kNN to work with than the original genre data that had lots of combinations. By simplifying this column, the distance calculations in the model will have more meaning. If we notice that some genres are still very rare or if our model isn’t working well, we can always come back and group those rare genres into an \"other\" category to make things even simpler.\n",
    "\n",
    "\n",
    "For the `top_lang` column, we’ve also made things easier by keeping only the main language for each movie. But some languages only show up a few times, which can overly-complicate the distance calculations in the model. To fix this, we should group these less common languages into an \"other\" category, just like we did for the `country` column. This helps the most important languages have meaning and avoids over-complicating the model with the ones that don’t appear often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb462c86",
   "metadata": {
    "id": "eb462c86"
   },
   "source": [
    "The cell below contains the code to collapse the `top_lang` column reassign any languages with less occurances than the threshold to have the value 'other'.\n",
    "\n",
    "> *Hint: Look at the variable assignment in the cell below to identify where the threshold for grouping languages is set to help answer **question 3**. Notice where this is used in the line below the does the actual collapsing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680d244",
   "metadata": {
    "id": "e680d244"
   },
   "outputs": [],
   "source": [
    "#collapse top_lang\n",
    "\n",
    "threshold = 10\n",
    "model_data['top_lang'] = model_data['top_lang'].apply(lambda x: x if model_data['top_lang'].value_counts()[x] > threshold else 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716d5c6",
   "metadata": {
    "id": "3716d5c6"
   },
   "source": [
    "### Reformat columns\n",
    "\n",
    "For kNN modeling, each column in your dataset should be in a format that the algorithm can easily understand and compare. This means:\n",
    "\n",
    "- **Numeric columns** (like `budget_x`, `revenue`, and `date_x`) should contain numbers only, and be formatted as such so the model can measure distances between values. We also need to scale these columns so that the values are in the same range, which ensures all features contribute equally rather than letting large-range variables dominate.\n",
    "- **Categorical columns** (like `country`, `top_genre`, and `top_lang`) should be converted into a format the model can use. One common way to do this is by creating dummy variables (also called one-hot encoding). For example, if you have a column called `top_genre` with values like \"Action\", \"Comedy\", or \"Drama\", you make a new column for each possible genre: one column for \"Action\", one for \"Comedy\", one for \"Drama\", and so on. In each new column, you put a `1` (or `True`) if the movie belongs to that genre, and a `0` (or `False`) if it does not. This allows for distances between values to be calculated.\n",
    "- **The variable you are predicting** (in this case `score`) needs to be categorical, such as \"high\" or \"low\", so kNN can classify new data into one of these categories. While kNN *can* be used for regression (predicting specific values), it is best suited for classification - which is how we will be using it here.\n",
    "\n",
    "By carefully reformatting each column, we ensure that kNN can accurately measure the \"distance\" between movies based on meaningful, comparable features—leading to better predictions and more reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501246c3",
   "metadata": {
    "id": "501246c3"
   },
   "source": [
    "#### Date\n",
    "\n",
    "The original `date_x` column contains full date information (month, day, year), but for our analysis we will simplify the data and make it easier for kNN to compare movies based on their release year. This also helps avoid unnecessary complexity from day/month differences that aren't meaningful for our predictions.\n",
    "\n",
    "This is another place where if we find our model does not perform well, we may want to revisit this decision to only keep the year, as the month a movie gets released may have some predictive power as well.\n",
    "\n",
    "**Step 1: Convert the `date_x` column to datetime format**  \n",
    "First, we use a pandas function to change the `date_x` column from a string (like \"03/02/2023\") into a pandas datetime object. This makes it easy to work with dates and extract parts like the year.\n",
    "\n",
    "**Step 2: Extract the year from the datetime column**  \n",
    "Once the column is in datetime format, we can use pandas to pull out just the year for each movie and save it in a new column called `year`. This gives us a simple numeric value that is much easier for kNN to use when comparing movies.\n",
    "\n",
    "By following these steps, we transform a complex date into a single, meaningful feature that helps our model focus on the most relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b52146",
   "metadata": {
    "id": "11b52146"
   },
   "outputs": [],
   "source": [
    "## Convert to datetime format\n",
    "\n",
    "model_data['date_x'] = pd.to_datetime(model_data['date_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8bd94",
   "metadata": {
    "id": "00f8bd94"
   },
   "outputs": [],
   "source": [
    "## extract the year and save as a new column 'year'\n",
    "# this will save as an integer\n",
    "\n",
    "model_data['year'] = model_data['date_x'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdd927",
   "metadata": {
    "id": "e6fdd927"
   },
   "source": [
    "#### Score\n",
    "\n",
    "To use kNN for classification, we need to convert the movie scores from numbers to categories. In this case, we will use a 2-level classification: \"high\" or \"low\" scores.\\\n",
    "This will allow us to predict whether a movie will receive a \"high\" or \"low\" score based on the characteristics in our dataset.\n",
    "\n",
    "In order to convert our score from numeric to categorical, we must determine a \"threshold\" to seperate the \"high\" and \"low\" scores.\\\n",
    "Use the density plot of the score distribution you created in LABS_06-Design to pick a threshold. Then:\n",
    " - Enter your chosen threshold into the code cell below before running it.\n",
    " - Provide an explanation for why you chose that threshold to answer **question 5**.\n",
    "\n",
    "> ***Remember**: This is another situation where there is no \"right answer\" on what to choose.*\\\n",
    "*This is a decision point where you should make an informed choice and note that you can adjust it later if your model performance warrants it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c5567",
   "metadata": {
    "id": "758c5567",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "outputId": "c74dad92-777e-4142-84f0-bd58d1aeed6c"
   },
   "outputs": [],
   "source": [
    "## reformat score\n",
    "\n",
    "score_threshold = 90\n",
    "model_data['score'] = model_data['score'].apply(lambda x: 'high' if model_data['score'][x] > score_threshold else 'low')\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06890bc",
   "metadata": {
    "id": "a06890bc"
   },
   "source": [
    "The score variable is now stored as strings of \"high\" or \"low\", but for kNN modeling, it must be converted and saved as a categorical variable because kNN groups data based on distinct labels. If the score is stored as a string, the algorithm may treat each unique text as a separate class, but converting it to a categorical type ensures consistent, clear groupings for accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fde33e",
   "metadata": {
    "id": "28fde33e"
   },
   "outputs": [],
   "source": [
    "# reformat from string to category\n",
    "\n",
    "model_data['score'] = model_data['score'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c330d41",
   "metadata": {
    "id": "9c330d41"
   },
   "source": [
    "#### Scale Numeric Columns\n",
    "\n",
    "The [MinMaxScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) transforms all of our numeric columns to be on a scale of 0-1. This avoids any very large numbers (like `revenue` and `budget_x`) from overpowering the distance calculations and skewing the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d9cd2",
   "metadata": {
    "id": "7b0d9cd2"
   },
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = model_data.select_dtypes(include='number').columns\n",
    "\n",
    "# Scale numeric columns\n",
    "model_data[numeric_cols] = MinMaxScaler().fit_transform(model_data[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6d1fe",
   "metadata": {
    "id": "b8f6d1fe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "outputId": "4d9bda3f-d5e2-4a6d-a84c-4c3eb6060298"
   },
   "outputs": [],
   "source": [
    "## check the data types of each column\n",
    "# note that score is now a 'category'\n",
    "\n",
    "model_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb168c20",
   "metadata": {
    "id": "cb168c20"
   },
   "source": [
    "### Drop extraneous columns\n",
    "\n",
    "Some columns in our dataset are not useful for kNN modeling because they contain text, complex lists, or information that cannot be easily converted into numeric or categorical formats for distance calculations. For example, columns like `names`, `overview`, `crew`, and `orig_title` contain descriptive text or lists of people, which do not help the kNN algorithm calculate distances to compare movies in a meaningful way.\n",
    "\n",
    "Additionally, for columns that were adjusted—such as `date_x`, `genre`, and `orig_lang`: we created new, simplified versions (`year`, `top_genre`, and `top_lang`) that are more suitable for kNN. After these adjustments, we drop the original columns to avoid redundancy and ensure our model only uses clean, relevant features.\n",
    "\n",
    "By removing these extraneous columns, we streamline our dataset and focus on the features that will help kNN make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65048e",
   "metadata": {
    "id": "8e65048e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "1b5cceea-944d-45c1-81d7-fc664b21421e"
   },
   "outputs": [],
   "source": [
    "## Drop the columns we won't use\n",
    "\n",
    "model_data = model_data.drop(columns=['status', 'date_x', 'names', 'genre', 'overview', 'crew', 'orig_title', 'orig_lang'])\n",
    "# Export cleaned data to CSV for later use\n",
    "model_data.to_csv(\"imdb_movies_cleaned.csv\", index=False)\n",
    "\n",
    "#view the data now\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914abe4",
   "metadata": {
    "id": "4914abe4"
   },
   "source": [
    "### Seperate features from target\n",
    "\n",
    "It is best practice to separate the columns used for prediction from the column you want to predict into distinct variables. This makes your code easier to read and helps you avoid mistakes, like accidentally using the answer to help make predictions. Most machine learning tools expect you to give them features and targets separately, so organizing your data this way makes your workflow smoother and less confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca9279",
   "metadata": {
    "id": "93ca9279"
   },
   "outputs": [],
   "source": [
    "# features: all columns except 'score'\n",
    "features = model_data.drop('score', axis=1)\n",
    "\n",
    "# Target: score column\n",
    "target = model_data['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6cb18",
   "metadata": {
    "id": "ceb6cb18"
   },
   "source": [
    "#### Dummy variables\n",
    "\n",
    "Dummy variables are created by transforming each category in a column into its own separate column, where each row is marked with a 1 or 0 (coded as True or False) to indicate the presence or absence of that category. This process, called one-hot encoding, ensures that all categorical features are represented numerically, making them compatible with algorithms like kNN that rely on distance calculations.\n",
    "\n",
    "For example, the `country` column contains values like \"US\", \"AU\", and \"other\", one-hot encoding will create new columns: `country_US`, `country_AU`, and `country_other`. Each row will have True in the column matching its country and False in the others. Similarly, for the `top_genre` column with values \"Action\", \"Comedy\", and \"Drama\", new columns `top_genre_Action`, `top_genre_Comedy`, and `top_genre_Drama` are created, with True/False indicating the genre for each movie.\n",
    "\n",
    "By converting categorical data into dummy variables, we prepare our dataset for effective modeling and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44291a9d",
   "metadata": {
    "id": "44291a9d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "outputId": "bb5e413f-17c7-4a62-9b71-dd8be31bccf2"
   },
   "outputs": [],
   "source": [
    "## create dummy variables for the features dataframe\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# preview the new features dataframe\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20efbe42",
   "metadata": {
    "id": "20efbe42"
   },
   "source": [
    "### Train/Test split\n",
    "Splitting the data into a **train set** and a **test set** is essential for building reliable machine learning models. The train set provides patterns and relationships for the algorithm to 'learn', while the test set is kept separate to evaluate performance on new, unseen data. This process helps identify overfitting - when an algorithm fits the training data too closely and fails to generalize - and ensures that results reflect true predictive power. Comparing accuracy on both sets allows for a confident assessment of how well the approach will work in real-world scenarios.\n",
    "\n",
    "We use the [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function from scikit-learn to perform this split. This function randomly divides the dataset into training and testing subsets, making it easy to control the size of each set and ensure reproducibility.\n",
    "\n",
    "> Use the linked documentation and the code below to help answer **question 8**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8d629",
   "metadata": {
    "id": "ede8d629"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24bbab",
   "metadata": {
    "id": "8c24bbab"
   },
   "source": [
    "## Create the model\n",
    "\n",
    "To build our kNN model, we must create our model, then train, test, and evaluate it. These steps are explained in more detail below.\n",
    "\n",
    "**Step 1: Create model - Initialize the classifier object**  \n",
    "We create a kNN classifier object using [`KNeighborsClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). This sets up the algorithm and specifies the nearest neighbors to classify each movie.\n",
    "\n",
    "**Step 2: Train - Fit to the training data**  \n",
    "We train the kNN model by calling [`.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit). This step allows the classifier to learn patterns from the training data so it can make predictions.\n",
    "\n",
    "**Step 3: Test - Predict on the testing data**  \n",
    "We use the trained model to predict the score category (\"high\" or \"low\") for the movies in our test set with [`.predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict). This generates predictions for data the model has not seen before.\n",
    "\n",
    "**Step 4: Evaluate - Calculate the accuracy of the testing data predictions**  \n",
    "We evaluate how well our model performed by comparing the predicted categories to the actual categories in the test set using [`accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html). This gives us a percentage that reflects the proportion of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12785ee",
   "metadata": {
    "id": "d12785ee"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aae042",
   "metadata": {
    "id": "35aae042",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "outputId": "77718b4e-ef37-499c-eca2-392a12fdacb4"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "knn.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085d7b5",
   "metadata": {
    "id": "a085d7b5"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "target_predicted = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f76d9",
   "metadata": {
    "id": "fa8f76d9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "37ef3153-c405-46f9-b8a0-c4c96a321313"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848de74a",
   "metadata": {
    "id": "848de74a"
   },
   "source": [
    "## Your Turn: Adjust the model\n",
    "\n",
    "You will now explore how the number of neighbors (`k`) affects your kNN model's accuracy. Follow these steps:\n",
    "\n",
    "1. **Change the value of `n_neighbors`** in the cell where the kNN model is created. Try at least 5 different values.\n",
    "1. **For each k value**, run *all* model building cells:  \n",
    "    - Create the model  \n",
    "    - Train the model  \n",
    "    - Test the model  \n",
    "    - Evaluate the accuracy  \n",
    "1. **Record the accuracy** for each k value you try.\n",
    "1. **Choose the best k** based on your results and explain your reasoning to answer **quesiton 10**.\n",
    "\n",
    "> *Tip: The \"best\" k is usually the one that gives the highest accuracy on the test set, but consider if the accuracy is stable or if the model seems to be overfitting or underfitting at certain values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a3f20",
   "metadata": {
    "id": "785a3f20"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
