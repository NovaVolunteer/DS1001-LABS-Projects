{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0AyYFuiqH9t"
   },
   "source": [
    "# Fairness in Machine Learning Example\n",
    "\n",
    "In this notebook we will explore an example of unnmitigated machine learning to observe how a model performs for different protected classes. We will be using the Fairlearn package to calculate various metrics to help us understand how our model performs across different classes.\n",
    "\n",
    "Check out their user guide for more information on the package! https://fairlearn.org/v0.10/user_guide/fairness_in_machine_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFxzTi6KqH9v"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UVADS/DS1001/blob/main/code/Fairness_lab.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4az8YXARqH9v",
    "outputId": "34328a65-ddbc-4792-c2f4-75f8645a6d98",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# You will have to run this cell to install the fairlearn package we'll be using today. You should only have to do this once (unless you restart your runtime).\n",
    "\n",
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuAqeQCoqH9x"
   },
   "outputs": [],
   "source": [
    "## You may have to run this line if you get an error message when you run the cell under 'Load in and explore/clean up the data'\n",
    "## If you do, remove the # on the line below and run this cell\n",
    "\n",
    "# !pip install pandas==2.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDfbtB-NqH9x"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fairlearn.metrics\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import count, true_positive_rate, false_positive_rate, selection_rate, demographic_parity_ratio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) ## ignore deprecation warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaNPFwI2qH9x"
   },
   "source": [
    "# Adult Census Data\n",
    "\n",
    "In this model we will be using demographic variables from census data to predict whether someone makes >50k or <=50k using data from: https://archive.ics.uci.edu/dataset/2/adult. A truncated/precleaned version of this is accessible through the `fairlearn` package, so we will import it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpnnkzzpqH9x"
   },
   "source": [
    "### Load in and explore/clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfVNFO7pqH9y",
    "outputId": "d31d49e0-e10c-400b-fe08-5431079e5aef"
   },
   "outputs": [],
   "source": [
    "## import and view the data\n",
    "\n",
    "from fairlearn.datasets import fetch_adult\n",
    "census_raw = fetch_adult(as_frame=True)\n",
    "census = census_raw.frame #this grabs the data in a pd.dataframe format\n",
    "\n",
    "\n",
    "census.head() # this prints the first 5 lines so we can see the format of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgYAUyfSqH9y"
   },
   "outputs": [],
   "source": [
    "## create lists of categorical/numerical columns\n",
    "\n",
    "census_catcols = list(census.select_dtypes('category')) # categorical columns\n",
    "\n",
    "census_numcols = list(set(census.columns) - set(census_catcols)) # numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "govKQawhqH90",
    "outputId": "dbd9a3fe-c00c-4080-81d2-768399846b47"
   },
   "outputs": [],
   "source": [
    "## get some info on the numerical data - gives us a general idea of spread and center\n",
    "census.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCxFYFNgqH90",
    "outputId": "4de55f0f-c7d7-4e5a-aea5-15ffddbc07a5"
   },
   "outputs": [],
   "source": [
    "## Visualize the spread of numeric data\n",
    "\n",
    "fig, axs = plt.subplots(3,2)\n",
    "axs = axs.ravel()\n",
    "for idx,ax in enumerate(axs):\n",
    "    ax.hist(census[census_numcols[idx]])\n",
    "    ax.set_title(census_numcols[idx])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_3EKdjlqH91",
    "outputId": "b0c117e0-7817-41cf-9501-a6a07a12f9bb"
   },
   "outputs": [],
   "source": [
    "## info on the categorical data\n",
    "# This shows us the levels in the categories for the first 2 category columns\n",
    "\n",
    "for col in census_catcols[:2]:\n",
    "    print(census[col].value_counts(), \"\\n\")\n",
    "\n",
    "# Most of the columns have a ton of categories, we can combine some of them to collapse the categories.\n",
    "# Typically we don't want ot have more than 5ish categories in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elqCkpKTqH91",
    "outputId": "4858ac89-076c-4d91-9c2b-e19a474eef7b"
   },
   "outputs": [],
   "source": [
    "## Collapsing some categories...\n",
    "\n",
    "# combining similar working classes\n",
    "census['workclass'].replace(['Without-pay', 'Never-worked',], 'No-inc', inplace=True)\n",
    "census['workclass'].replace(['Local-gov', 'State-gov', 'Federal-gov'], 'Gov', inplace=True)\n",
    "# print(census['workclass'].value_counts())\n",
    "\n",
    "# making race binary White/Non-White\n",
    "census['race'] = (census.race.apply(lambda x: x if x == 'White' else \"Non-White\")).astype('category')\n",
    "# print(census['race'].value_counts())\n",
    "\n",
    "# combining similar education classes\n",
    "census['education'].replace(['11th', '10th', '9th', '12th',], 'Some-HS', inplace=True)\n",
    "census['education'].replace(['7th-8th', '5th-6th', '1st-4th', 'Preschool',], 'No-HS', inplace=True)\n",
    "census['education'].replace(['Assoc-voc', 'Assoc-acdm', 'Prof-school'], 'Continued Ed', inplace=True)\n",
    "census['education'].replace(['Bachelors', 'Masters', 'Doctorate'], 'College_+', inplace=True)\n",
    "# print(census['education'].value_counts())\n",
    "\n",
    "# combining similar marital statuses\n",
    "census['marital-status'].replace(['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse'], 'Married', inplace=True)\n",
    "census['marital-status'].replace(['Divorced', 'Separated', 'Widowed'], 'Was-Married', inplace=True)\n",
    "# print(census['marital-status'].value_counts())\n",
    "\n",
    "# keeping only the top 4 countries (based on number of observations), grouping all others into \"Other\" category\n",
    "top_country = census['native-country'].value_counts()[:5]\n",
    "census['native-country'] = (census['native-country'].apply(lambda x: x if x in top_country else \"Other\")).astype('category')\n",
    "# print(census['native-country'].value_counts())\n",
    "\n",
    "# keeping only the top 4 occupations (based on number of observations), grouping all others into \"Other\" category\n",
    "top_occ = census['occupation'].value_counts()[:5]\n",
    "census['occupation'] = (census['occupation'].apply(lambda x: x if x in top_occ else \"Other\")).astype('category')\n",
    "# print(census['occupation'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7ps6V_zqH91"
   },
   "source": [
    "##### A little more pre-processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shk_CGteqH91"
   },
   "outputs": [],
   "source": [
    "# Scale numbers, One hot encode categories\n",
    "\n",
    "census[census_numcols] = MinMaxScaler().fit_transform(census[census_numcols]) #scale the numerical values so they are all on the same scale\n",
    "census_onehot = pd.get_dummies(census, columns = census_catcols) # creates dummy variables to one-hot encode all categorical variables\n",
    "\n",
    "## One hot encoding creates a column for each category in a feature and assigns it a True/False value.\n",
    "## For example, the 'workclass' column will be broken up into a column for each category ('workclass_Gov', 'workclass_No-inc', etc).\n",
    "## A government workclass observation would have a True value in the 'workclass_Gov' column and a False value in all the other workclass columns.\n",
    "## This is a common strategy you'll see in machine learning - also with 1/0 values instead of True/False (respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgaEHT2uqH91",
    "outputId": "c6705720-eefe-47ca-f303-b1cd99babaf9"
   },
   "outputs": [],
   "source": [
    "census_onehot.drop(['class_<=50K', 'race_White', 'sex_Male'], axis=1, inplace=True) # drop binary category duplicates\n",
    "census_onehot.head() # visualize what the data looks like after being scaled/one hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIyU9ZtwqH91"
   },
   "source": [
    "Finally, we need to split it into a training set (to build our model) and testing set (to see how it performs on data it was not trained on).\n",
    "\n",
    "We also need to split our data into our target (\"class_>50K\" - denoted as y) and features (everything else - denoted as x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noe5c1iUqH92"
   },
   "outputs": [],
   "source": [
    "# split the data into train and test for model\n",
    "\n",
    "#seperate into features and target (\"class_>50K\")\n",
    "census_x = census_onehot.loc[:, census_onehot.columns != \"class_>50K\"]\n",
    "census_y = census_onehot.loc[:, census_onehot.columns == \"class_>50K\"]\n",
    "\n",
    "#train/test split (75/25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(census_x, census_y, test_size=0.25, random_state=9658)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msxRqWjtqH92"
   },
   "source": [
    "# Now, let's look at our data and model and evaluate the fairness\n",
    "\n",
    "You will answer the following questions using the code/output below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqTUddkTqH92"
   },
   "source": [
    "## Questions\n",
    "\n",
    "### 1. The metrics we will be using in this lecture are True Positive Rate, False Positive Rate, Selection Rate, Demographic Parity Ratio, and Equalized Odds Ratio.\n",
    "\n",
    "### 2. What are the protected classes in this dataset? Are these classes equally represented in the data?\n",
    "\n",
    "### 3. For any given protected class, what group is being favored in the model?\n",
    "\n",
    "### 4. Based on the fairness metrics you observed, is the model fair â€“ why/why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivwq4WFdqH92"
   },
   "source": [
    "### Looking at the data distribution\n",
    "\n",
    "Type the name of the protected class you'd like to explore in the quotes below. Be sure to use the exact name (case sensitive!) of the column from the data frame above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WMd4zHFqH92",
    "outputId": "2aaeec5b-9708-4b08-e351-def828b6f32a"
   },
   "outputs": [],
   "source": [
    "protectedClass = \"education\" # type the protected class you'd like to explore in the quotes here\n",
    "\n",
    "print(census[protectedClass].value_counts()) #print the number of observations in each class\n",
    "\n",
    "#visualize the difference in class representation\n",
    "plt.bar(census[protectedClass].value_counts().index.values, census[protectedClass].value_counts().values)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel(protectedClass)\n",
    "plt.title(f\"Proctected Class Distribution - {protectedClass}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYkAZoGjqH92"
   },
   "source": [
    "## Model buliding\n",
    "\n",
    "It's finally time to build our model!\n",
    "\n",
    "We'll be building a simple logistic regression model to predict if a person makes more than 50k a year.\n",
    "\n",
    "Basically, a logistic regression works by calculating a *probability* of an observation being in a specified class for the target variable. So in this case, our model will produce a probability of a person making more than 50k. This probability is compared to a threshold value, and if the probability is above the threshold is will be categorized as a positive outcome (in this case, making more thank 50k). For more information on logistic regressions, check out this IBM page: https://www.ibm.com/topics/logistic-regression#:~:text=Logistic%20regression%20estimates%20the%20probability,given%20dataset%20of%20independent%20variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4zDOM9lqH92",
    "outputId": "b4b98605-dbc5-497d-a5a2-75895a24e6ce"
   },
   "outputs": [],
   "source": [
    "## train model\n",
    "\n",
    "lreg = LogisticRegression() #initialize a logistic regression model\n",
    "lreg.fit(X_train, y_train) #train this model using our training data\n",
    "\n",
    "y_pred = lreg.predict(X_test) # store predicted values for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDoJScCzqH92"
   },
   "source": [
    "#### Average accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3vJPuOfqH93",
    "outputId": "2475284a-6d15-4591-dc4f-15b4e2d315b3"
   },
   "outputs": [],
   "source": [
    "print(\"Average accuracy on test data:\\t\",round(lreg.score(X_test, y_test)*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke407wZGqH93"
   },
   "source": [
    "### Fairness Metrics\n",
    "\n",
    "We are using the Fairlearn package in Python.\n",
    "\n",
    "You will need to understand what the metric used below mean and how they are calculated. You can find information on the functions used in their documentation: https://fairlearn.org/v0.10/api_reference/index.html#module-fairlearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlMAg60zqH93"
   },
   "outputs": [],
   "source": [
    "# Construct a function dictionary with the metrics we'd like for each class\n",
    "my_metrics = {\n",
    "    'true positive rate' : true_positive_rate,\n",
    "    'false positive rate' : false_positive_rate,\n",
    "    'selection rate' : selection_rate,\n",
    "    'count' : count\n",
    "}\n",
    "# Construct a MetricFrame for race\n",
    "mf_race = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=X_test[\"race_Non-White\"]\n",
    ")\n",
    "\n",
    "# Construct a MetricFrame for sex\n",
    "mf_sex = MetricFrame(\n",
    "    metrics=my_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=X_test[\"sex_Female\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYsI2yu4qH93",
    "outputId": "6d5dd75b-e0d0-4545-b03b-132ccbc01a23"
   },
   "outputs": [],
   "source": [
    "# Display the by_group breakdown for race\n",
    "print(\"Metrics by Race:\")\n",
    "print(mf_race.by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-P6tqA40qH93"
   },
   "outputs": [],
   "source": [
    "def create_confmatrix(y_test, y_pred):\n",
    "    '''\n",
    "    creates a confusion matrix with more descriptive formatting\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() # grab the individual values\n",
    "\n",
    "    # create a data frame with the values in the correct spots\n",
    "    conf_matrix = pd.DataFrame({'predicted positive': [tp, fp],\n",
    "                                'predicted negative': [fn, tn]},\n",
    "                                index=['actual positive','actual negative'])\n",
    "\n",
    "    # return the dataframe to be saved/viewed\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMdzOLRUqH93"
   },
   "source": [
    "#### Overall metrics\n",
    "\n",
    "Here is the confusion matrix for the model overall with *counts* for the true positive, false positive, true negative, and false negative.\n",
    "\n",
    "For more information on confusion matrices, check out the wiki page: https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJw_DkdPqH93",
    "outputId": "7d564f47-c518-453d-b83a-d02582ed17c4"
   },
   "outputs": [],
   "source": [
    "# overall confusion matrix\n",
    "print(\"Confusion matrix for all test data:\")\n",
    "create_confmatrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXmN2_K9qH94"
   },
   "source": [
    "This code works because it's displaying the overall (aggregate) fairness metrics from the `MetricFrame` object `mf_race` in a formatted DataFrame.\n",
    "\n",
    "Here's why it works:\n",
    "\n",
    "1. **`mf_race.overall`**: This attribute contains a dictionary-like object with the overall metrics (averaged across all groups) that were calculated when the `MetricFrame` was created. These metrics include:\n",
    "    - true positive rate\n",
    "    - false positive rate\n",
    "    - selection rate\n",
    "    - count\n",
    "\n",
    "2. **`pd.DataFrame(..., columns = [\"overall\"])`**: Converts the metrics dictionary into a pandas DataFrame with a single column named \"overall\"\n",
    "\n",
    "3. **`.T`**: Transposes the DataFrame so that instead of having metrics as rows, they become columns, making it easier to read and compare with the by-group breakdowns shown in later cells\n",
    "\n",
    "The result is a clean, single-row DataFrame showing the model's performance metrics aggregated across all test data, which serves as a baseline for comparison when you look at how the model performs for different protected classes (race and sex) in the cells below.\n",
    "\n",
    "This is particularly useful in fairness analysis because you can compare these overall metrics to the by-group metrics (like `mf_race.by_group`) to identify disparities in model performance across different demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAaOlW6JqH94"
   },
   "outputs": [],
   "source": [
    "## The overall metrics. You'll use these to compare to with the metrics broken down by each protected class below.\n",
    "## Think about how the differing performance would impact that group based on your understanding of each metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp1Gcvt5qH94"
   },
   "source": [
    "Now we can look at fairness metrics for each protected class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1yh6BzFqH94"
   },
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqffEkC4qH94",
    "outputId": "066b29cb-2a05-4f34-ea1a-8f0bf642bc4a"
   },
   "outputs": [],
   "source": [
    "## metrics broken down by race classes. Compare these to the metrics above.\n",
    "mf_race.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSJ7heZgqH94"
   },
   "source": [
    "Definitions\n",
    "\n",
    "1. Demographic Parity Ratio: Measures whether different groups (Male vs Female) are selected at similar rates by the model. A ratio of 1.0 means perfect parity - both groups are predicted to earn >50K at the same rate. Values below 1.0 indicate one group is favored over another. For example, 0.5 means one group is selected at half the rate of the other.\n",
    "2. Equality of Odds Ratio: The equalized odds ratio of 1 means that all groups have the same true positive, true negative, false positive, and false negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj3C4NHmqH94",
    "outputId": "01760d06-1a21-45b2-8124-5666f0972655"
   },
   "outputs": [],
   "source": [
    "# Derived fairness metrics. Be sure you understand the scale and meaning of these.\n",
    "\n",
    "dpr_race = fairlearn.metrics.demographic_parity_ratio(y_test, y_pred, sensitive_features=X_test.filter(regex=\"race.*\"))\n",
    "print(\"Demographic Parity ratio:\\t\", dpr_race)\n",
    "\n",
    "eodds_race = fairlearn.metrics.equalized_odds_ratio(y_test, y_pred, sensitive_features=X_test.filter(regex=\"race.*\"))\n",
    "print(\"Equalized Odds ratio:\\t\\t\", eodds_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StaeXcPuqH94"
   },
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMdzoGJSqH95",
    "outputId": "c47d9288-1737-4fd0-e67c-9e49304ad0a0"
   },
   "outputs": [],
   "source": [
    "## metrics broken down by sex classes. Compare these to the metrics above.\n",
    "\n",
    "mf_sex.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72EFju-PqH95",
    "outputId": "80b47650-056d-41c3-96b5-78f3bf1f711f"
   },
   "outputs": [],
   "source": [
    "# Derived fairness metrics. Be sure you understand the scale and meaning of these.\n",
    "\n",
    "dpr_sex = fairlearn.metrics.demographic_parity_ratio(y_test, y_pred, sensitive_features=X_test.filter(regex=\"sex.*\"))\n",
    "print(\"Demographic Parity ratio:\\t\", dpr_sex)\n",
    "\n",
    "eodds_sex = fairlearn.metrics.equalized_odds_ratio(y_test, y_pred, sensitive_features=X_test.filter(regex=\"sex.*\"))\n",
    "print(\"Equalized Odds ratio:\\t\\t\", eodds_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsbtW0sHqH95",
    "outputId": "a7aaacf2-6c24-4c21-c778-452734ea7dab"
   },
   "outputs": [],
   "source": [
    "# Let's break down the demographic parity ratio for sex with detailed visualizations\n",
    "\n",
    "# First, let's see the selection rates for each sex group\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMOGRAPHIC PARITY RATIO EXPLANATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThe Demographic Parity Ratio compares the selection rates\")\n",
    "print(\"between different groups (Male vs Female).\")\n",
    "print(\"\\nFormula: min(rate_group1, rate_group2) / max(rate_group1, rate_group2)\")\n",
    "print(\"A value of 1.0 = perfect parity (both groups selected equally)\")\n",
    "print(\"A value < 1.0 = disparity exists (one group favored over another)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate selection rates for each sex group\n",
    "male_mask = X_test[\"sex_Female\"] == False\n",
    "female_mask = X_test[\"sex_Female\"] == True\n",
    "\n",
    "male_selection_rate = y_pred[male_mask].sum() / len(y_pred[male_mask])\n",
    "female_selection_rate = y_pred[female_mask].sum() / len(y_pred[female_mask])\n",
    "\n",
    "print(f\"\\nðŸ“Š SELECTION RATES BY SEX:\")\n",
    "print(f\"Male (predicted >50K):   {male_selection_rate:.4f} ({male_selection_rate*100:.2f}%)\")\n",
    "print(f\"Female (predicted >50K): {female_selection_rate:.4f} ({female_selection_rate*100:.2f}%)\")\n",
    "print(f\"\\nDemographic Parity Ratio: {dpr_sex:.4f}\")\n",
    "print(f\"Interpretation: Females are selected at {dpr_sex*100:.2f}% the rate of males\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CaeAoYTqH95",
    "outputId": "7691b9cf-b9fe-403c-96ed-abf4651dc914"
   },
   "outputs": [],
   "source": [
    "# Visualization 1: Selection rates comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "\n",
    "# Plot 1: Selection rates bar chart\n",
    "categories = ['Male', 'Female']\n",
    "selection_rates = [male_selection_rate, female_selection_rate]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "axes[0].bar(categories, selection_rates, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('Selection Rate (Predicted >50K)', fontsize=11)\n",
    "axes[0].set_title('Selection Rates by Sex\\n(What % are predicted to earn >50K?)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylim(0, max(selection_rates) * 1.2)\n",
    "for i, v in enumerate(selection_rates):\n",
    "    axes[0].text(i, v + 0.01, f'{v*100:.1f}%', ha='center', fontweight='bold')\n",
    "axes[0].axhline(y=male_selection_rate, color='gray', linestyle='--', alpha=0.5, label='Male rate (reference)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Counts of predictions\n",
    "male_positive = y_pred[male_mask].sum()\n",
    "male_negative = (~y_pred[male_mask]).sum()\n",
    "female_positive = y_pred[female_mask].sum()\n",
    "female_negative = (~y_pred[female_mask]).sum()\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar(x - width/2, [male_positive, female_positive], width, label='Predicted >50K', color='#2ecc71', alpha=0.8)\n",
    "axes[1].bar(x + width/2, [male_negative, female_negative], width, label='Predicted â‰¤50K', color='#95a5a6', alpha=0.8)\n",
    "axes[1].set_ylabel('Count of Predictions', fontsize=11)\n",
    "axes[1].set_title('Distribution of Predictions by Sex', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(categories)\n",
    "axes[1].legend()\n",
    "\n",
    "# Add count labels\n",
    "for i, (pos, neg) in enumerate([(male_positive, male_negative), (female_positive, female_negative)]):\n",
    "    axes[1].text(i - width/2, pos + 50, str(pos), ha='center', fontweight='bold', fontsize=9)\n",
    "    axes[1].text(i + width/2, neg + 50, str(neg), ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Plot 3: Visual representation of disparity\n",
    "axes[2].barh(['Female', 'Male'], [female_selection_rate, male_selection_rate],\n",
    "             color=['#e74c3c', '#3498db'], alpha=0.7, edgecolor='black')\n",
    "axes[2].set_xlabel('Selection Rate', fontsize=11)\n",
    "axes[2].set_title(f'Disparity Visualization\\nDPR = {dpr_sex:.4f}', fontsize=12, fontweight='bold')\n",
    "axes[2].axvline(x=male_selection_rate, color='gray', linestyle='--', alpha=0.5, label='Male rate (reference)')\n",
    "\n",
    "# Add arrows showing the gap\n",
    "gap = male_selection_rate - female_selection_rate\n",
    "axes[2].annotate('', xy=(male_selection_rate, 0), xytext=(female_selection_rate, 0),\n",
    "                arrowprops=dict(arrowstyle='<->', color='red', lw=2))\n",
    "axes[2].text((male_selection_rate + female_selection_rate)/2, 0.05,\n",
    "             f'Gap: {gap*100:.1f}%', ha='center', color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional statistics\n",
    "print(f\"\\nðŸ“ˆ DETAILED STATISTICS:\")\n",
    "print(f\"\\nSample sizes:\")\n",
    "print(f\"  Male:   {male_mask.sum()} observations\")\n",
    "print(f\"  Female: {female_mask.sum()} observations\")\n",
    "\n",
    "print(f\"\\nPredictions breakdown:\")\n",
    "print(f\"  Male predicted >50K:   {male_positive} ({male_selection_rate*100:.1f}%)\")\n",
    "print(f\"  Female predicted >50K: {female_positive} ({female_selection_rate*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâš ï¸  FAIRNESS ASSESSMENT:\")\n",
    "if dpr_sex >= 0.8:\n",
    "    print(\"âœ“ Passes the 80% rule (commonly used fairness threshold)\")\n",
    "else:\n",
    "    print(f\"âœ— Fails the 80% rule (DPR should be â‰¥ 0.8)\")\n",
    "    print(f\"  Current DPR ({dpr_sex:.4f}) indicates significant disparity\")\n",
    "    print(f\"  Females are underrepresented in positive predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mrti4NOnqH95",
    "outputId": "46103728-34eb-439b-d8be-6acf7a276d81"
   },
   "outputs": [],
   "source": [
    "# Equalized Odds breakdown for sex (similar style to DPR breakdown above)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EQUALIZED ODDS RATIO EXPLANATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Equalized Odds requires similar error and success rates across groups.\")\n",
    "print(\"We compare True Positive Rate (TPR), False Positive Rate (FPR),\")\n",
    "print(\"True Negative Rate (TNR), and False Negative Rate (FNR) for Male vs Female.\")\n",
    "print(f\"Equalized Odds Ratio (overall): {eodds_sex:.4f}\")\n",
    "print(\"A value of 1.0 indicates parity across all these rates.\\n\")\n",
    "\n",
    "y_true = y_test[\"class_>50K\"]\n",
    "\n",
    "def group_confusion(mask):\n",
    "    tp = np.sum((y_pred == True)  & (y_true == True)  & mask)\n",
    "    fp = np.sum((y_pred == True)  & (y_true == False) & mask)\n",
    "    tn = np.sum((y_pred == False) & (y_true == False) & mask)\n",
    "    fn = np.sum((y_pred == False) & (y_true == True)  & mask)\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "male_tp, male_fp, male_tn, male_fn = group_confusion(male_mask)\n",
    "female_tp, female_fp, female_tn, female_fn = group_confusion(female_mask)\n",
    "\n",
    "def rates(tp, fp, tn, fn):\n",
    "    tpr = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else np.nan\n",
    "    tnr = tn / (tn + fp) if (tn + fp) else np.nan\n",
    "    fnr = fn / (fn + tp) if (fn + tp) else np.nan\n",
    "    return tpr, fpr, tnr, fnr\n",
    "\n",
    "male_tpr, male_fpr, male_tnr, male_fnr = rates(male_tp, male_fp, male_tn, male_fn)\n",
    "female_tpr, female_fpr, female_tnr, female_fnr = rates(female_tp, female_fp, female_tn, female_fn)\n",
    "\n",
    "print(\"Group performance rates:\")\n",
    "print(f\"Male   -> TPR:{male_tpr:.3f} FPR:{male_fpr:.3f} TNR:{male_tnr:.3f} FNR:{male_fnr:.3f}\")\n",
    "print(f\"Female -> TPR:{female_tpr:.3f} FPR:{female_fpr:.3f} TNR:{female_tnr:.3f} FNR:{female_fnr:.3f}\\n\")\n",
    "\n",
    "# Ratios (smaller / larger for each metric)\n",
    "def ratio(a, b):\n",
    "    return min(a, b) / max(a, b) if (a > 0 and b > 0) else np.nan\n",
    "\n",
    "tpr_ratio = ratio(male_tpr, female_tpr)\n",
    "fpr_ratio = ratio(male_fpr, female_fpr)\n",
    "tnr_ratio = ratio(male_tnr, female_tnr)\n",
    "fnr_ratio = ratio(male_fnr, female_fnr)\n",
    "\n",
    "print(\"Per-metric parity ratios (min/max):\")\n",
    "print(f\"TPR ratio: {tpr_ratio:.3f}\")\n",
    "print(f\"FPR ratio: {fpr_ratio:.3f}\")\n",
    "print(f\"TNR ratio: {tnr_ratio:.3f}\")\n",
    "print(f\"FNR ratio: {fnr_ratio:.3f}\")\n",
    "\n",
    "worst_ratio = np.nanmin([tpr_ratio, fpr_ratio, tnr_ratio, fnr_ratio])\n",
    "print(f\"\\nWorst-case parity ratio (approx basis of Equalized Odds): {worst_ratio:.3f}\")\n",
    "print(f\"Reported Equalized Odds Ratio: {eodds_sex:.4f}\\n\")\n",
    "\n",
    "print(\"Fairness assessment:\")\n",
    "if eodds_sex >= 0.8:\n",
    "    print(\"Passes a common 0.8 threshold.\")\n",
    "else:\n",
    "    print(\"Fails a common 0.8 threshold; substantial disparity exists.\")\n",
    "\n",
    "# Visualization\n",
    "fig2, axarr = plt.subplots(1, 3, figsize=(16,5))\n",
    "\n",
    "# Panel 1: TPR/FPR comparison\n",
    "metrics_names = [\"TPR\",\"FPR\",\"TNR\",\"FNR\"]\n",
    "male_vals = [male_tpr, male_fpr, male_tnr, male_fnr]\n",
    "female_vals = [female_tpr, female_fpr, female_tnr, female_fnr]\n",
    "x_pos = np.arange(len(metrics_names))\n",
    "axarr[0].bar(x_pos - 0.2, male_vals, width=0.4, label=\"Male\", color=\"#3498db\")\n",
    "axarr[0].bar(x_pos + 0.2, female_vals, width=0.4, label=\"Female\", color=\"#e74c3c\")\n",
    "axarr[0].set_xticks(x_pos)\n",
    "axarr[0].set_xticklabels(metrics_names)\n",
    "axarr[0].set_ylabel(\"Rate\")\n",
    "axarr[0].set_title(\"Error/Success Rates by Sex\")\n",
    "axarr[0].legend()\n",
    "\n",
    "# Panel 2: Confusion matrix counts per group (normalized)\n",
    "def norm_counts(tp, fp, tn, fn):\n",
    "    total = tp + fp + tn + fn\n",
    "    return [tp/total, fp/total, tn/total, fn/total]\n",
    "male_norm = norm_counts(male_tp, male_fp, male_tn, male_fn)\n",
    "female_norm = norm_counts(female_tp, female_fp, female_tn, female_fn)\n",
    "labels_cm = [\"TP\",\"FP\",\"TN\",\"FN\"]\n",
    "x2 = np.arange(len(labels_cm))\n",
    "axarr[1].bar(x2 - 0.2, male_norm, 0.4, label=\"Male\", color=\"#3498db\")\n",
    "axarr[1].bar(x2 + 0.2, female_norm, 0.4, label=\"Female\", color=\"#e74c3c\")\n",
    "axarr[1].set_xticks(x2)\n",
    "axarr[1].set_xticklabels(labels_cm)\n",
    "axarr[1].set_ylabel(\"Proportion\")\n",
    "axarr[1].set_title(\"Normalized Confusion Components\")\n",
    "axarr[1].legend()\n",
    "\n",
    "# Panel 3: Parity ratios\n",
    "parity_vals = [tpr_ratio, fpr_ratio, tnr_ratio, fnr_ratio]\n",
    "axarr[2].bar(metrics_names, parity_vals, color=\"#8e44ad\", alpha=0.7)\n",
    "axarr[2].axhline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "axarr[2].axhline(0.8, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "axarr[2].set_ylim(0, 1.05)\n",
    "axarr[2].set_ylabel(\"Parity Ratio (min/max)\")\n",
    "axarr[2].set_title(f\"Per-Metric Parity Ratios\\nWorst={worst_ratio:.3f} | EO={eodds_sex:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
